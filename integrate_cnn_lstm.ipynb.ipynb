{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9b78bf3-acc8-481a-b1a9-df3f4758c753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load CNN model (for road blockage detection)\n",
    "cnn_model = load_model(r'D:/jupyter_nbk_project/cnn/dataset/cnn_model.h5')\n",
    "\n",
    "# Load LSTM model (for traffic volume prediction)\n",
    "lstm_model = load_model(r'D:/jupyter_nbk_project/disaster_relief_ai/notebooks/traffic_forecast_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4ec522c-31fb-4e50-90ca-313c4a25750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Model Loaded Successfully:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_12               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_13               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_12               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_12 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_18 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_13               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_13 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_19 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m1,605,760\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_14 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,626,179</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,626,179\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,625,729</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,625,729\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Model Loaded Successfully:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │          \u001b[38;5;34m12,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,453</span> (126.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,453\u001b[0m (126.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,451</span> (126.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,451\u001b[0m (126.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"CNN Model Loaded Successfully:\")\n",
    "cnn_model.summary()\n",
    "\n",
    "print(\"\\nLSTM Model Loaded Successfully:\")\n",
    "lstm_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aec41c6e-17cd-4334-a5f2-de559cd9a074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa5df9f7-7f97-473d-856b-b6d9c2616ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
      "CNN Prediction (Road Blocked = 0 / Not Blocked = 1): [[0.0013491]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step\n",
      "LSTM Prediction (Traffic Volume): [[0.5457015]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example dummy image input (must match training shape: e.g., 64x64x3)\n",
    "dummy_image = np.random.rand(1, 64, 64, 3)  # (batch_size, height, width, channels)\n",
    "\n",
    "# Predict\n",
    "cnn_result = cnn_model.predict(dummy_image)\n",
    "print(\"CNN Prediction (Road Blocked = 0 / Not Blocked = 1):\", cnn_result)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create dummy input: batch_size=1, timesteps=10, features=10\n",
    "dummy_series = np.random.rand(1, 10, 10)\n",
    "\n",
    "# Predict using the LSTM model\n",
    "lstm_result = lstm_model.predict(dummy_series)\n",
    "print(\"LSTM Prediction (Traffic Volume):\", lstm_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16fac610-5a42-438f-be16-57e7ad4ba036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "CNN Raw Prediction: [[8.755058e-06]]\n",
      "CNN Classification: Blocked\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step\n",
      "LSTM Scaled Prediction (Traffic Volume): [[0.08958688]]\n",
      "LSTM Real Traffic Volume Prediction: [[639.6649]]\n",
      "LSTM Real Traffic Volume Prediction: [[639.6649]]\n",
      "Final Decision: Road is BLOCKED – Do NOT dispatch. Consider rerouting.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load models\n",
    "cnn_model = load_model(r'D:/jupyter_nbk_project/cnn/dataset/cnn_model.h5')\n",
    "lstm_model = load_model(r'D:/jupyter_nbk_project/disaster_relief_ai/notebooks/traffic_forecast_model.h5')\n",
    "\n",
    "# --- CNN Prediction ---\n",
    "img_path = r'D:/jupyter_nbk_project/dataset/test/Blocked/Blocked-66-_png.rf.585d06d02fc58ee4c396fc5d4d34f0a3.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))  # Match model input size\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "# Class indices\n",
    "class_indices = {'Blocked': 0, 'NotBlocked': 1}\n",
    "index_to_label = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Prediction\n",
    "cnn_result = cnn_model.predict(img_array)\n",
    "print(\"CNN Raw Prediction:\", cnn_result)\n",
    "\n",
    "# If sigmoid activation (single output)\n",
    "predicted_class_index = 1 if cnn_result[0][0] > 0.5 else 0\n",
    "cnn_label = index_to_label[predicted_class_index]\n",
    "\n",
    "print(\"CNN Classification:\", cnn_label)\n",
    "# --- LSTM Prediction ---\n",
    "csv_path = r'D:/jupyter_nbk_project/disaster_relief_ai/data/merged/final_dataset.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "features = ['traffic_volume', 'temp', 'rain_1h', 'snow_1h', 'clouds_all',\n",
    "            'Temperature (C)', 'Apparent Temperature (C)', 'Humidity',\n",
    "            'Wind Speed (km/h)', 'Pressure (millibars)']\n",
    "\n",
    "if not all(col in df.columns for col in features):\n",
    "    raise ValueError(\"Some required feature columns are missing in the CSV file.\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df[features])\n",
    "\n",
    "time_steps = 10\n",
    "input_sequence = scaled_data[-time_steps:].reshape(1, time_steps, len(features))\n",
    "\n",
    "lstm_result = lstm_model.predict(input_sequence)\n",
    "print(\"LSTM Scaled Prediction (Traffic Volume):\", lstm_result)\n",
    "\n",
    "# Optional: inverse transform traffic volume\n",
    "scaler_traffic = MinMaxScaler()\n",
    "traffic_scaled = scaler_traffic.fit_transform(df[['traffic_volume']])\n",
    "predicted_real_value = scaler_traffic.inverse_transform(lstm_result)\n",
    "print(\"LSTM Real Traffic Volume Prediction:\", predicted_real_value)\n",
    "# After your prediction code...\n",
    "\n",
    "print(\"LSTM Real Traffic Volume Prediction:\", predicted_real_value)\n",
    "\n",
    "# Define threshold for traffic volume\n",
    "traffic_threshold = 500  # adjust this threshold as appropriate\n",
    "\n",
    "# Decision making\n",
    "if cnn_label == \"Blocked\":\n",
    "    final_decision = \"Road is BLOCKED – Do NOT dispatch. Consider rerouting.\"\n",
    "elif cnn_label == \"NotBlocked\" and predicted_real_value[0][0] > traffic_threshold:\n",
    "    final_decision = \"Road is OPEN, but traffic is HIGH – Dispatch with caution.\"\n",
    "elif cnn_label == \"NotBlocked\" and predicted_real_value[0][0] <= traffic_threshold:\n",
    "    final_decision = \"Road is OPEN and traffic is LOW – Safe to dispatch.\"\n",
    "\n",
    "print(\"Final Decision:\", final_decision)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0b5106a-9bc9-4486-a1c3-0006b1061a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected CNN input shape: (None, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected CNN input shape:\", cnn_model.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "242d8d9b-915d-4e52-93da-30e84e6cb0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step\n",
      "CNN Raw Prediction: [[0.9992683]]\n",
      "CNN Classification: NotBlocked\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594ms/step\n",
      "LSTM Scaled Prediction (Traffic Volume): [[0.08958688]]\n",
      "LSTM Real Traffic Volume Prediction: [[639.6649]]\n",
      "Final Decision: Road is OPEN, but traffic is HIGH – Dispatch with caution.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load models\n",
    "cnn_model = load_model(r'D:/jupyter_nbk_project/cnn/dataset/cnn_model.h5')\n",
    "lstm_model = load_model(r'D:/jupyter_nbk_project/disaster_relief_ai/notebooks/traffic_forecast_model.h5')\n",
    "\n",
    "# --- CNN Prediction ---\n",
    "img_path = r'D:/jupyter_nbk_project/dataset/test/NotBlocked/NotBlocked-10-_png.rf.566adf00d9b858c4d5f5f7791a73e16c.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))  # Match model input size\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "# Class indices\n",
    "class_indices = {'Blocked': 0, 'NotBlocked': 1}\n",
    "index_to_label = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Prediction\n",
    "cnn_result = cnn_model.predict(img_array)\n",
    "print(\"CNN Raw Prediction:\", cnn_result)\n",
    "\n",
    "# If sigmoid activation (single output)\n",
    "predicted_class_index = 1 if cnn_result[0][0] > 0.5 else 0\n",
    "cnn_label = index_to_label[predicted_class_index]\n",
    "\n",
    "print(\"CNN Classification:\", cnn_label)\n",
    "# --- LSTM Prediction ---\n",
    "csv_path = r'D:/jupyter_nbk_project/disaster_relief_ai/data/merged/final_dataset.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "features = ['traffic_volume', 'temp', 'rain_1h', 'snow_1h', 'clouds_all',\n",
    "            'Temperature (C)', 'Apparent Temperature (C)', 'Humidity',\n",
    "            'Wind Speed (km/h)', 'Pressure (millibars)']\n",
    "\n",
    "if not all(col in df.columns for col in features):\n",
    "    raise ValueError(\"Some required feature columns are missing in the CSV file.\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df[features])\n",
    "\n",
    "time_steps = 10\n",
    "input_sequence = scaled_data[-time_steps:].reshape(1, time_steps, len(features))\n",
    "\n",
    "lstm_result = lstm_model.predict(input_sequence)\n",
    "print(\"LSTM Scaled Prediction (Traffic Volume):\", lstm_result)\n",
    "# After your prediction code...\n",
    "\n",
    "print(\"LSTM Real Traffic Volume Prediction:\", predicted_real_value)\n",
    "\n",
    "# Define threshold for traffic volume\n",
    "traffic_threshold = 500  # adjust this threshold as appropriate\n",
    "\n",
    "# Decision making\n",
    "if cnn_label == \"Blocked\":\n",
    "    final_decision = \"Road is BLOCKED – Do NOT dispatch. Consider rerouting.\"\n",
    "elif cnn_label == \"NotBlocked\" and predicted_real_value[0][0] > traffic_threshold:\n",
    "    final_decision = \"Road is OPEN, but traffic is HIGH – Dispatch with caution.\"\n",
    "elif cnn_label == \"NotBlocked\" and predicted_real_value[0][0] <= traffic_threshold:\n",
    "    final_decision = \"Road is OPEN and traffic is LOW – Safe to dispatch.\"\n",
    "\n",
    "print(\"Final Decision:\", final_decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0be30e4-121d-449a-89f3-5d2b50d72eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Road Segment: ('A', 'B')\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
      "CNN Prediction: NotBlocked\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
      "LSTM Traffic Prediction: 9.531848788261414\n",
      "\n",
      "Road Segment: ('A', 'C')\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "CNN Prediction: Blocked\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "LSTM Traffic Prediction: 10.538667440414429\n",
      "\n",
      "Road Segment: ('C', 'D')\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "CNN Prediction: Blocked\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "LSTM Traffic Prediction: 11.916244626045227\n",
      "\n",
      "Road Segment: ('D', 'E')\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "CNN Prediction: NotBlocked\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "LSTM Traffic Prediction: 11.927263140678406\n",
      "Last LSTM predicted traffic value: 1.3252515\n",
      "\n",
      "Final Road Conditions:\n",
      "('A', 'B'): {'status': 'Open - Low Traffic', 'traffic': np.float64(9.53)}\n",
      "('A', 'C'): {'status': 'Blocked', 'traffic': np.float64(10.54)}\n",
      "('C', 'D'): {'status': 'Blocked', 'traffic': np.float64(11.92)}\n",
      "('D', 'E'): {'status': 'Open - High Traffic', 'traffic': np.float64(11.93)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# === Load Pre-trained Models ===\n",
    "cnn_model = load_model(r'D:/jupyter_nbk_project/cnn/dataset/cnn_model.h5')\n",
    "lstm_model = load_model(r'D:/jupyter_nbk_project/disaster_relief_ai/notebooks/traffic_forecast_model.h5')\n",
    "\n",
    "# === Setup Class Mappings ===\n",
    "class_indices = {'Blocked': 0, 'NotBlocked': 1}\n",
    "index_to_label = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# === Feature List for LSTM ===\n",
    "features = ['traffic_volume', 'temp', 'rain_1h', 'snow_1h', 'clouds_all',\n",
    "            'Temperature (C)', 'Apparent Temperature (C)', 'Humidity',\n",
    "            'Wind Speed (km/h)', 'Pressure (millibars)']\n",
    "scaler = MinMaxScaler()\n",
    "dummy_data = pd.DataFrame(np.tile(np.arange(10), (10, 1)).T, columns=features)\n",
    "scaler.fit(dummy_data)  # Fitting on dummy just to use transform\n",
    "\n",
    "# === Inference Function ===\n",
    "def get_road_conditions(road_segments, cnn_images, traffic_series, threshold=10):\n",
    "    conditions = {}\n",
    "\n",
    "    for road in road_segments:\n",
    "        print(f\"\\nRoad Segment: {road}\")\n",
    "        img_path = cnn_images[road]\n",
    "        traffic_value = traffic_series[road]\n",
    "\n",
    "        # --- CNN Part ---\n",
    "        img = image.load_img(img_path, target_size=(64, 64))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "        cnn_result = cnn_model.predict(img_array)\n",
    "        cnn_pred = 1 if cnn_result[0][0] > 0.5 else 0\n",
    "        cnn_label = index_to_label[cnn_pred]\n",
    "\n",
    "        print(\"CNN Prediction:\", cnn_label)\n",
    "\n",
    "        # --- LSTM Part ---\n",
    "        full_features = []\n",
    "        for t in traffic_value:\n",
    "            full_features.append([t, 10, 0, 0, 50, 20, 20, 50, 10, 1000])\n",
    "        \n",
    "        full_features_df = pd.DataFrame(full_features, columns=features)\n",
    "        full_features_scaled = scaler.transform(full_features_df)\n",
    "        full_features_scaled = np.array(full_features_scaled).reshape(1, 10, len(features))\n",
    "        \n",
    "        lstm_result = lstm_model.predict(full_features_scaled)\n",
    "        \n",
    "        # Assuming lstm_result shape is (1, 10)\n",
    "        last_pred = lstm_result[0, -1]  # if shape is (1, 10)\n",
    "        \n",
    "        zeros_pad = np.zeros((1, len(features) - 1))\n",
    "        scaled_pred = np.hstack([np.array([[last_pred]]), zeros_pad])\n",
    "        predicted_traffic = scaler.inverse_transform(scaled_pred)[0][0]\n",
    "        \n",
    "        print(\"LSTM Traffic Prediction:\", predicted_traffic)\n",
    "\n",
    "        # --- Final Decision ---\n",
    "        # Adjust the threshold as per your prediction scale\n",
    "        if cnn_label == \"Blocked\":\n",
    "            status = \"Blocked\"\n",
    "        elif cnn_label == \"NotBlocked\" and predicted_traffic > threshold:\n",
    "            status = \"Open - High Traffic\"\n",
    "        else:\n",
    "            status = \"Open - Low Traffic\"\n",
    "\n",
    "        conditions[road] = {\n",
    "            \"status\": status,\n",
    "            \"traffic\": round(predicted_traffic, 2)\n",
    "            \n",
    "        }\n",
    "    print(\"Last LSTM predicted traffic value:\", last_pred)\n",
    "\n",
    "    return conditions\n",
    "\n",
    "\n",
    "# === Define input data with 4 roads ===\n",
    "road_segments = [('A', 'B'), ('A', 'C'), ('C', 'D'), ('D', 'E')]\n",
    "\n",
    "cnn_images = {\n",
    "    ('A', 'B'): r'D:/jupyter_nbk_project/dataset/test/NotBlocked/NotBlocked-22-_png.rf.03390c7a640ae2c0069aedfad0ce7334.jpg',\n",
    "    ('A', 'C'): r'D:/jupyter_nbk_project/dataset/test/Blocked/Blocked-66-_png.rf.585d06d02fc58ee4c396fc5d4d34f0a3.jpg',\n",
    "    ('C', 'D'): r'D:/jupyter_nbk_project/dataset/test/Blocked/Blocked-173-_png.rf.4477292d43126db1ba4df9e6564c63e3.jpg',\n",
    "    ('D', 'E'): r'D:/jupyter_nbk_project/dataset/test/NotBlocked/NotBlocked-10-_png.rf.566adf00d9b858c4d5f5f7791a73e16c.jpg'\n",
    "}\n",
    "\n",
    "traffic_series = {\n",
    "    ('A', 'B'): [700, 680, 710, 690, 705, 710, 715, 700, 690, 680],\n",
    "    ('A', 'C'): [200, 195, 210, 215, 220, 225, 230, 200, 190, 180],\n",
    "    ('C', 'D'): [400, 390, 405, 410, 420, 430, 410, 400, 390, 385],\n",
    "    ('D', 'E'): [350, 345, 360, 355, 370, 365, 375, 380, 360, 355]\n",
    "}\n",
    "\n",
    "# === Run the Integrated Predictions ===\n",
    "road_conditions = get_road_conditions(road_segments, cnn_images, traffic_series, threshold=10)\n",
    "\n",
    "# === Print Results ===\n",
    "print(\"\\nFinal Road Conditions:\")\n",
    "for road, info in road_conditions.items():\n",
    "    print(f\"{road}: {info}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6b420-3205-4ec5-84ad-626de4c1f80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
